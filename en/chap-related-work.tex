\chapter{Related work}\label{chap-related-work}
This chapter gives a basic overview of all relevant tools and background information researched during work on this thesis. Firstly, it gives literary background necessary to make reader familiar with rhyme and its different types, to know what to look for before we start detecting them. Secondly, it describes existing tools for rhyme detection and visualization, and the different approaches they took. Lastly, it explains current state-of-art tools for lyrics generation.


\section{Rhyme types and literary devices}

There are many different definitions for what a rhyme is. It is described as "a word that has the same last sound as another word" by Cambridge Dictionary (\cite{walter2008cambridge}) or a "literary device, featured particularly in poetry, in which identical or similar concluding syllables in different words are repeated" by \cite{literarydevices2020}. The definition of what a good rhyme is even changes for different languages and time periods (\cite{zhirmunsky2013introduction}). For example, full identity in sound is highly valued in French (\textit{\gls{rime_riche}}), but less valued in English (perfect rhyme requires leading consonant sounds to differ). Some authors refrain from giving an exact definition and instead leave it to reader's intuition (\cite{plechavc2018collocation}). We will define rhyme through its different types, what will be helpful for detection later. 

\subsection{Basic rhyme types}
\paragraph{Perfect rhyme} (also true rhyme, or sometimes just "rhyme") is the most common and superior type of rhyme. It requires two conditions to be met:

\begin{itemize}
	\item last stressed vowel and all following sounds are identical
	\item immediately preceding sounds differ
\end{itemize}

It is also the only rhyme for which the definitions are consistent (for example, see \cite{bain1867manual}, \cite{vanphonological}, \cite{bergman2017litcharts}, Wikipedia\footnote{\url{https://en.wikipedia.org/wiki/Rhyme}}). It can be further distinguished depending on how many syllables are involved:

\begin{itemize}
	\item \textbf{Masculine} (also single, monosyllabic) -- "the commonest kind of rhyme, between single stressed syllables at the ends of verse" (\cite{oxforddict2008literary}). 
	Examples: 
	
	fly /\textipa{\underline{flaI}}/ -- sky /\textipa{\underline{skaI}}/
	
	before /\textipa{bi.\underline{fO:r}}/ -- explore /\textipa{Iks.\underline{plO:r}}/
	\footnote{For the examples, we are using IPA transcriptions because it is more comfortable for human readers.}
	\footnote{Stressed syllables are underlined. Syllables are separated with a dot.}
	
	\item \textbf{Feminine} (also double) -- "a rhyme on two syllables, the first stressed and the second unstressed" (\cite{oxforddict2008literary}). Examples: 
	
	bitten /\textipa{\underline{bI}.t@n}/ -- written /\textipa{\underline{rI}.t@n}/
	
	lazy /\textipa{\underline{leI}.zi}/ -- crazy /textipa{\underline{kreI}.zi}/
	
	\item \textbf{Dactylic} (also triple) -- "a rhyme on three syllables, the first stressed and the others unstressed"(\cite{oxforddict2008literary}). Examples: 
	
	amorous /\textipa{\underline{æ}.m@r.@s}/ -- glamorous /\textipa{\underline{glæ}.m@r.@s}/
	
	vanity /\textipa{\underline{væ}.nI.ti}/ -- humanity /\textipa{hju:-\underline{mæ}.nI.ti})/
	
\end{itemize}

\paragraph{Imperfect rhyme} (also slant or half rhyme)  rhymes "the stressed syllable of one word with the unstressed syllable of another word" (\cite{bergman2017litcharts}). Examples: 

cabbage /\textipa{\underline{kæ}.bIdZ}/ -- ridge /\textipa{\underline{rIdZ}}/

painting /\textipa{\underline{peIn}.tIN}/ -- ring /\textipa{\underline{rIN}}/

\noindent In other sources, definitions differ -- for example \cite{literarydevices2020} calls this effect "feminine rhyme".  On the other hand, \cite{oxforddict2008literary} and \cite{britannica} use the term "imperfect rhyme" for end-line consonance (see definition below) and \cite{vanphonological} uses it for end-line assonance (see definition below). For the purpose of this thesis, we would like to keep rhyme types disjoint. Therefore we will require the sounds in the imperfect rhyme to be identical, except for the stress. This will differentiate it from \textit{forced rhyme} (see below).


\paragraph{Unaccented rhyme} (also weakened rhyme) "occurs when the relevant syllable of the rhyming word is unstressed" (\cite{britannica}). Examples: 

hammer /\textipa{\underline{hæ}.m@r}/ -- carpenter /\textipa{\underline{kA:r}.p@n.t@r}/

\noindent The difference opposed to imperfect rhyme is that here \gls{rhyming_part}s of both words are unstressed. However, for simplicity, in the scope of this thesis we will include this category under \textit{imperfect rhymes}.


\paragraph{Identical rhyme} (also \gls{rime_riche}) is "a kind of rhyme in which the rhyming elements include matching consonants before the stressed vowel sounds." This includes "rhyming of two words with the same sound and sometimes the same spelling but different meanings e.g.:

 seen /\textipa{\underline{sin}}/ -- scene /\textipa{\underline{si:n}}/
 
 The term also covers word‐endings where the consonant preceding the stressed vowel sound is the same: 
 
 compare /\textipa{k@m.\underline{pEr}}/ -- despair /\textipa{dIs.\underline{pEr}}/." (\cite{oxforddict2008literary})
 
 It is generally considered not as good as perfect rhyme because it is too predictable for the listener\footnote{\url{https://literaryterms.net/rhyme/}}. However, all rhyme detection tools as well as gold data that we will be using (annotated by professionals) include identity in perfect rhymes. To make the comparison and evaluation with our tool easier, we will do so as well.

\paragraph{Forced rhyme} (also near rhyme) "includes words with a close but imperfect match in sound in the final syllables" \cite{bergman2017litcharts}. Examples: 

green /\textipa{\underline{gri:n}}/ -- fiend /\textipa{\underline{fi:nd}}/

hide /\textipa{\underline{haId}}/ -- mind /\textipa{\underline{maInd}}/

\noindent This includes the case when spelling is changed in order to make the rhyme work, e.g.:

 truth /\textipa{\underline{truT}}/ -- endu'th /\textipa{en.\underline{duT}}/ (a contraction of "endureth")
 
 It can also refer to using unnatural word order to get the rhyming word at the end of the line (\cite{bergman2017litcharts}) but we will not make use of this interpretation in this thesis.

\subsection{Other literary devices}
This is a short overview of other literary devices that closely correlate with forced rhyme and may, according so some sources, be considered a rhyme. We will conservatively exclude these from our classification and focus solely on rhymes occurring at the end of verse.

\paragraph{Assonance} is "repetition of stressed vowel sounds within words with different end consonants" (\cite{britannica}). Examples:	

quite /\textipa{\underline{kwaIt}}/ -- like /\textipa{\underline{laIk}}/

free /\textipa{\underline{fri:}}/ -- breeze /\textipa{\underline{bri:z}}/

\noindent When used at the end of verse with ending consonants having a similar sound, it is equal to forced rhyme. However, the term itself defines a literary device applicable anywhere in the poem, even in the middle of the verse. Some sources classify it as rhyme, giving it various names (\cite{vanphonological}, \cite{bergman2017litcharts}, and others).

\paragraph{Consonance} is "the recurrence or repetition of identical or similar consonants" (\cite{britannica}). Examples: 

country (\textipa{\underline{k@n}-tri}) / contra (\textipa{\underline{kAn}-tr@})

hickory dickory dock (\textipa{\underline{hI}-k@-ri \underline{dI}-k@-ri \underline{dAk}})

\noindent Similarly as assonance, it applies to repetition of consonants in any part of the verse. When seen at the end of verse, it can be considered a rhyme and again, various terms are used -- perhaps the most common is "pararhyme" (\cite{britannica}, \cite{oxforddict2008literary}).
\newline

The last two terms may seem as more of a tool for poets than songwriters. Surprisingly, they have found their way into song lyrics and have become a standard in genres like hip hop according to \cite{vanphonological}. From the creative point of view, it is not less sophisticated rather it enriches rhyme as we know it (\cite{brogan2016poeticterms}).


Other rhyme types exist e.g. eye rhyme where "the spellings of the rhyming elements match, but the sounds do not, e.g. love /\textipa{\underline{l@v}}/ -- prove /\textipa{\underline{pru:v}}/" (\cite{oxforddict2008literary}). We do not consider them relevant for song lyrics or the purpose of this thesis.



\section{Rhyme detection tools}\label{rhyme_detection_tools}
We have defined what to look for, and now we will focus on how to do it. According to \cite{plechac2017presentation}, there are 4 methods for rhyme detection. We will describe each one and evaluate existing tools. For our use case, it is important that we can use the tool for automatic evaluation - there must be a way to run it with code whether it would be an API, or an executable script, or as a library/module. Another requirement is for it to be able to run on a block of text and generate rhyme scheme as a result. Lastly, it has to be free and preferably open-source.

\subsection{Naive rule-based approach} 
The simplest approach is to compare for identity of phonemes at the end of lines. Noticeably,  this only detects perfect rhymes and identity. Nevertheless the result will seem decent because it has 100\% recall and notices all ``obvious'' rhymes. Another downside of this approach is its limitation to the size of the dictionary. There are many rhyming dictionaries (of various quality and size) to choose from but the vast majority of them uses or enhances CMU dictionary\footnote{\url{http://www.speech.cs.cmu.edu/cgi-bin/cmudict}}. 
\subsubsection*{Pronouncing and CMU dictionary}
Pronouncing\footnote{\url{https://pypi.org/project/pronouncing/}} is a Python library providing an interface for CMU Pronouncing Dictionary. One possibility is to install CMUdict directly, search for pronunciations for both words and compare then. \textit{Pronouncing} searches the dictionary automatically for a given word and returns a list of rhyming words. However, the list is truncated and probably better suited for writer's inspiration only.


\subsection{Advanced rule-based approach}
\subsubsection*{Datamuse}
\subsubsection*{Rhyme Genie}
\subsubsection*{SPARSAR}
SPARSAR (\cite{Delmonte2014}) is also a very interesting tool for poetry analysis and expressive Text-to-speech conversion. It is originally designed for a thorough examination of a very strictly structured Shakespeare's sonnets. To achieve this, it has to run analyses on many levels -- and these results can be used to analyze any poem. It looks at the poem on three levels: phonetic (pronunciation, consonant and vowel tongue position, assonances, etc.), poetic (metrical structure, rhyme schemes, acoustic length, etc.), and semantic (sentiment, methaphorically linked words, anaphora, etc.).

User can choose between a window application with graphs and diagrams or a \gls{headless_mode} with .xml output files. Its main disadvantage for our use case is that it is written in Prolog and therefore is very strict on the input format and runs only under a specific older version of Ubuntu. 

\subsection{Similarity (distance) based approach}
\subsection{Machine learning}
\subsubsection*{EM algorithm}
\cite{reddy2011unsupervised} proposed a language-independent model for finding rhyme schemes in poetry. They created an unsupervised model based on EM algorithm that assigns the most probable rhyme scheme for each sequence of line-final words. It achieved good results when tested on annotated English and French corpus with poetry from 15\textsuperscript{th} to 20\textsuperscript{th} century. However its big pitfall lies in the fact that it is biased towards the rhyme schemes from golden data. It has a predefined set of all rhyme schemes found in tested data and those are the only ones it chooses from. For illustration, in a 14-line stanza it can choose from 90 schemes which is only 0.00005\% of all possible options. In 29\% of cases from French corpus it has only one choice.\footnote{\url{http://versologie.cz/talks/2017basel/}}

\subsubsection*{RhymeTagger}
\cite{plechavc2018collocation} came with a collocation-driven alternative named RhymeTagger. It uses the same dataset as the previous approach with addition of a larger Czech poetry corpus\footnote{\url{https://github.com/versotym/corpusCzechVerse}}. Each line-final word is transcribed into phonetic transcription and split into components -- \gls{syllable_peak} for each syllable and \gls{consonant_clusters} in between. In the "expectation" step, probabilities for each component pair are calculated based on their co-occurrence in line-final words, e.g. conditional probability of rhyme based on peak component pair \textipa{@U:@U} will be very high but for consonant component pair k:r quite low. These statistics for component pairs are then used in the "maximization" step to calculate the probability for line-final word pair as a combined probability of all their components (paired by means of usual association measure). If the probability of two words is above a given threshold they are considered a rhyme. After all such pairs are classified, probabilities are iteratively recalculated in the EM cycle. 

For words that were not successfully classified with this method, there is a fallback. The author observed that some words are now pronounced differently than they were during the Shakespearean era they were written in and therefore using current pronunciation dictionaries may ruin the original rhyme, e.g. original near (\textipa{nE:r}) / there (\textipa{DE:r}) vs. contemporary near (\textipa{nI:r}) / there (\textipa{DE:r}). Original pronunciation can be therefore inferred from words with similar orthography. He calculated rhyme probability given final character trigrams, which helped achieve higher recall. Although other methods may have better precision, collocation-driven approach wins in recall as seen in \ref{screenshotRT}. This method does not take into account meter.

For evaluation, they used precision, recall and F-score calculated as follows:

\[PRECISION=\frac{true\ positives}{true\ positives+false\ positives}\]

\[RECALL=\frac{true\ positives}{true\ positives+false\ negatives}\]

\[F-SCORE=\frac{2*PRECISION*RECALL}{PRECISION+RECALL}\]

For an intuitive view, the reader can imagine precision as how many of algorithm's rhymes were actually rhymes and recall as how many rhymes were discovered. F-score describes the trade-off between the two.

\begin{figure}[h]\centering
	\includegraphics[scale=0.4]{../img/plechac_eval.png}
	\caption[RhymeTagger evaluation]{Evaluation of RhymeTagger on English corpus in comparison with EM algorithm and simple rule-based approach. The x axis is the year when the tested poem was written, the y axis are the evaluation scores as described above. Reproduced from \cite{plechac2017presentation}.}
	\label{screenshotRT}
\end{figure}
\todo[inline]{Popisat preco nejdu ich data pouzit na testovanie mojej detekcie rymov}

\subsubsection*{Deep-speare}
As a part of their \gls{sonnet} \gls{quatrain} generating model, \cite{lau2018deep} have implemented a Rhyme component that identifies and generates rhymes. It is a unidirectional forward \gls{LSTM} (\cite{hochreiter1997long}) that learns to separate rhyming word pairs from non-rhyming. They generate input by pairing one line-final word with the other three from the same quatrain. Since the rhyme scheme of a \gls{sonnet} \gls{quatrain} is always \textit{abab} this will result in one rhyming pair and two non-rhyming. Additional non-rhyming pairs are generated with random word sampling. Then the model with margin-based loss learns the margin separating the best pair from all the others. It returns a cosine similarity score that estimates how well do two words rhyme.

To evaluate this model, authors used phoneme matching with CMUdict \footnote{\url{http://www.speech.cs.cmu.edu/cgi-bin/cmudict}} and the EM model from \cite{reddy2011unsupervised} trained on their own data and they were able to outperform both based on F1 score.



\section{Visualization tools}
In the following section, we will describe existing visualization tools for poetry. Software mentioned below focuses on poems, however song lyrics can be considered just a more structurally relaxed version of a regular poem.
\subsection{Poem Viewer}
Quite complex and comprehensive visualization tool is Poem Viewer \cite{Abdul2013}. With no need for complicated installations it is easily available for the writers as a web-based application as shown in Figure \ref{screenshotPV}. Unfortunately, at the time of writing this thesis the upload of custom text was not working. Luckily, this is still an ongoing project so this might be just a temporary issue. Nevertheless there are some default poems available to demonstrate this software's capabilities.
\begin{figure}[h]\centering
	\includegraphics[scale=0.24]{../img/ScreenshotPV.png}
	\caption{Screenshot from Poem Viewer tool -- visualizing Love by Elizabeth Barrett Browning.}\label{screenshotPV}
\end{figure}

\begin{figure}[h]\centering
	\includegraphics[scale=0.4]{../img/snapshotPV_options.pdf}
	\caption{Available options and their default mappings in Poem Viewer.}\label{screenshotPV-options}
\end{figure}

Most of the analyzed features (shown in Figure \ref{screenshotPV-options} focus on the phonetic aspects of the poem. After phonetic transcription to IPA users can analyze consonant features, vowel length and position, stress, syllables, word classes and sentiment using color codes and markers. A second layout offers six different graphs/animations of tongue positions during each verse. Arcs are used to mark end rhyme, alliteration, assonance, consonance, their particular frequencies and repeating words.


Overall this software, although very elaborate, appears crammed and confusing for an inexperienced user. Moreover, it is perhaps better suited for its original use case -- a well-structured poem -- than less regular song lyrics.

\subsection{SPARSAR}
SPARSAR (\cite{Delmonte2014}) is also a very interesting tool for poetry analysis and expressive Text-to-speech conversion. It is originally designed for a thorough examination of a very strictly structured Shakespeare's sonnets. To achieve this, it has to run analyses on many levels -- and these results can be used to analyze any poem. It looks at the poem on three levels: phonetic (pronunciation, consonant and vowel tongue position, assonances, etc.), poetic (metrical structure, rhyme schemes, acoustic length, etc.), and semantic (sentiment, methaphorically linked words, anaphora, etc.).

User can choose between a window application with graphs and diagrams or a \gls{headless_mode} with .xml output files. Its main disadvantage for our use case is that it is written in Prolog and therefore is very strict on the input format and runs only under a specific older version of Ubuntu. 

\subsection{ProseVis}
This Java desktop visualization tool by \cite{Clement2013} analyzes text through
parts-of-speech, phonemes, stress, tone, and break index. These features are extracted using OpenMary Text-to-speech system (\cite{Schroder2006}) and predictive classification. The authors believe their visualization will present the features to user in a more human readable form (\cite{prosevis2017sourceforge}).

\begin{figure}[h]\centering
	\includegraphics[scale=0.24]{../img/prosevis.png}
	\caption[Comparison of two poems in ProseVis]{Comparison of two poems in ProseVis. Reproduced from \cite{prosevis2017sourceforge}.}\label{screenshotProsevis}
\end{figure}

\subsection{Poemage and RhymeDesign}
Poemage (\cite{McCurdy2015poemage}) and RhymeDesign (\cite{McCurdy2015}) are both open-source applications with focus on analysis of sonic devices and sonic topology in poetry. Poemage\footnote{\url{http://www.sci.utah.edu/~nmccurdy/Poemage/}} focuses on complex structures of words connected through some sonic or linguistic resemblance across the space of the poem. It is available for MacOS or Windows with a web version currently under development. In MacOS application RhymeDesign -- which also provides the backend for Poemage -- users can enter their poem and query for one of the default rhyme types or choose a custom rhyme type.

\begin{figure}[h]\centering
	\includegraphics[scale=0.24]{../img/poemage.pdf}
	\caption{An example analysis in Poemage.}\label{screenshotPoemage}
\end{figure}

\subsection{Ambiances}
This software is unique in the fact that the analysis is integrated in the process of writing. As described in the paper \cite{Meneses2015}, writers enter the poem, receive a visualization and can control this visualization with body and hand gestures which in turn influence the poem. By such interconnection the authors aim to make Ambiances a part of the writing process and give it a chance to influence the final result. However, the actual software does not seem to be openly available.


\section{Generation tools}\label{generation_tools}

Generation of text, especially artistic, is a very challenging task for a machine. As we observed the outputs of exiting tools, we found that the most common flaws include lack of creativity, unnatural and frequent change of the subject, and incoherence. Generation of song lyrics is basically a more specified branch of text generation. Similarly, it can be distinguished into two main methods -- rule-based and machine learning. 

Rule-based models are inherently very complex and the output is often limited to certain structure or topic. They usually require the user to input starting configuration, whether it is genre, topic, time period, amount and type of rhymes, phrases, etc. They tend to be less creative but better at rhyming and following the form and structure. To achieve that, they may use rhyming dictionaries (see section \ref{rhyme_detection_tools}). Simpler ones just use a large set of pre-written templates, e.g. MasterPiece Generator\footnote{\url{https://www.song-lyrics-generator.org.uk/}}. For this thesis, we will focus on generation using artificial intelligence (AI).

\subsection{Generating using AI}
There are many algorithms in AI that can be used for lyrics generation and 
\subsubsection*{Deepspeare}
\subsubsection*{EM algorithm by Reddy and Knight}
\subsubsection*{GPT-2}
Generative pre-trained Transformer version 2 (GPT-2) is an ... It was created by AI-based research laboratory named OpenAI.

This model was trained on (and evaluated against) WebText, a dataset consisting of the text contents of 45 million links posted by users of the ‘Reddit’ social network. WebText is made of data derived from outbound links from Reddit and does not consist of data taken directly from Reddit itself. Before generating the dataset we used a blocklist to ensure we didn’t sample from a variety of subreddits which contain sexually explicit or otherwise offensive content.

To get a sense of the data that went into GPT-2, we’ve published a list of the top 1,000 domains present in WebText and their frequency. The top 15 domains by volume in WebText are: Google, Archive, Blogspot, GitHub, NYTimes, Wordpress, Washington Post, Wikia, BBC, The Guardian, eBay, Pastebin, CNN, Yahoo!, and the Huffington Post.
1.5 billion parameters: the fourth and largest GPT-2 version. We have also released 124 million, 355 million, and 774 million parameter models.
\cite{radford2019gpt2}
\subsubsection*{GPT-3}


Originally, this thesis intended to focus more on lyrics generation. However, as our research of works in this field shows, there is an abundance of tools for purpose. Users can just choose a tool that fits their needs. Creating one tool that would be better or more versatile would either require more computing power or literary knowledge, and is above the scope of a master thesis. Therefore, we shifted our main focus to automatic rhyme detection and evaluation, which seems to be far less explored and more interesting topic.

\todo[inline]{Is this a good argumentation or should I leave it out?}


\cite{lau2018deep} - learns rhyme automatically, for sonnets, results indistinguishable, apart from expert evaluation, missing emotion
\todo[inline]{generation by Reddy}
\todo[inline]{
	- deepspeare - ako oni generuju
	- generovanie pomocou slovnikov
	- gpt2, gtp3 \cite{brown2020language}
	- pravidlove generatory - tym sa nebudeme venovat, spomenut priklad}