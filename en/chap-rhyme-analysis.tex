
\chapter{Rhyme detection}
Detecting rhymes may seem like a simple task at first, but looking into details one discovers many problems that need to be addressed. As we have seen in chapter \ref{chap-related-work}, it is not a well-defined task so boundaries need to be set.
\todo[inline]{Describe the original attempt with SPARSAR.- uviest priklady pesnicky, ktora sa zjavne rymuje ale urcilo ju to zle; priklad slova na ktorom sparsar spadne }
\todo[inline]{sucast zadania ze to bude bez zvukovej stranky hoci to vplyv ma}
\todo[inline]{pri popise taggeru dat typy rymov, ktore nezvlada}


\footnote{\url{http://phylonetworks.blogspot.com/2020/07/automated-detection-of-rhymes-in-texts.html}}
- points out most works focus on rhyme schemes in well structured poetry instead of common rhymes in text
- where to draw the line between intended rhyme and accidental word similarity

\section{Using available tools for detection}
The simplest approach would be to use one of the tools described in section \ref{rhyme_detection_tools}. We want a detector that is free, strong (detects more than perfect rhymes), and offers headless mode (we could run it automatically from code). Ruling out unsuitable tools, we are left with Rhyme Tagger and SPARSAR. Rhyme Tagger is easy-to-use but only outputs rhyme scheme. To be able to automatically evaluate the rhyming quality of a song, we would need more information like stress or rhyme type.

SPARSAR, on the other hand, has a very rich and detailed output. Although it is lacking documentation, the \textit{xml} output format is quite descriptive to understand what most of the values represent. It seemed promising so we attempted to pursue this path.

To bridge the outdated system requirements, we contacted the authors for a newer build (for Ubuntu 19.1). They were very helpful and soon we were able to run it on our computer.

bolo nutne pridat diakritiku - punctuator2
tazky parsing xmlka

failed on contractions like I'mma, y'all, yo', 'em

\begin{table}[h!]
	\centering
	\begin{tabular}{c c c} 
		Scheme & Line & \begin{tabular}{@{}c@{}}Last word's pronunciation \\ (as assigned by SPARSAR)\end{tabular}  \\ [0.5ex] 
		\hline
		a & Pulled out from the station & s-t-ey-sh-ah-n \\ 
		h & fifteen after two & t-uw \\
		a &	300 miles away from Vegas & v-ey-g-ah-s\\
		b & We had nothin better to do & d-uw\\
	\end{tabular}
	\caption{Example of incorrect scheme assignment by SPARSAR. Excerpt from song \textit{Good Life}.}
	\label{sparsar_wrong_scheme}
\end{table}

\section{Defining the requirements}\label{defining_the_requirements}
\todo[inline]{Někde byste ale měla napsat, že předpokládáte 1 verš na řádku (a žádné rýmy uvnitř verše).}
\todo[inline]{Definovat si slovnik - rymujuce riadky, componenty}

\section{Pronunciation}
Unlike many other languages, English does not have a straightforward pronunciation rules. Therefore to be able to assess rhymes, we need to transcribe our text into a phonetic alphabet first. There are two commonly used alphabets to choose from -- IPA and ARPAbet. The original International Phonetic Alphabet (IPA) used since 1888 uses one UNICODE character to encode each phoneme and it is commonly used for example in dictionaries. Since it uses non-ASCII characters, ARPAbet was developed as an equivalent for computers. It has two versions: 1-character that uses upper-case and lower-case letters and 2-character version where each phoneme is represented by one or more upper-case ASCII characters (\cite{lea1980trends})(see Table\ref{pronunciation_table} for comparison). We will be using the 2-character ARPAbet because it is used by the CMUdict.

\begin{table}[h!]
	\centering
	\begin{tabular}{c c c c} 
		Example word & IPA & 1-character ARPAbet & 2-character ARPAbet \\ [0.5ex] 
		\hline
		st\textbf{o}ry & \textipa{O} & c & AO \\ 
		bu\textbf{tt}er & \textipa{R} & F & DX \\
	\end{tabular}
	\caption{Comparison of different pronunciation alphabets.}
	\label{pronunciation_table}
\end{table}

Carnegie Mellon University Pronouncing Dictionary (CMUdict) is an open-source pronunciation dictionary.\footnote{\url{http://www.speech.cs.cmu.edu/cgi-bin/cmudict}} Currently it contains 134,373 words (including their inflections) and their pronunciations in 2-character ARPAbet. 
For each word, there is one or several possible pronunciations in North American English including stress markers for primary, secondary or no stress. For the implementation, we used its Python wrapper package \textit{cmudict} \footnote{\url{https://pypi.org/project/cmudict/}}. To use this we need to strip the input of punctuation and convert it to lower case.

CMUdict is a large dictionary and it includes also slang words so it should cover most of our input. To test this, we looked at all last words on each line of our data (since those are the important ones for rhyme analysis) and we found out that 5.52\% of them are not in CMU dictionary. These included:

\begin{itemize}
	\item uncommon words, e.g. superglue, redundantly
	\item misspelled words, e.g. decsion, girlfren
	\item numbers
	\item foreign words, e.g. revoluccion, ecolli
	\item interjections and onomatopoeia, e.g. shoooshooo, woahwoah
\end{itemize}

Also, we applied some further data preprocessing that ensured more words in data would be found in the dictionary. We replaced the closing quotation mark "’" with the typewriter apostrophe "'" since only the second variant of apostrophe is accepted by CMUdict. We replaced hyphen "-" with a space " " to separate the hyphen-connected compound words into individual component words that have a higher chance of being found in the dictionary than the full version.

Clearly, these modifications did not help us with all of the words. For the remainder, we used grapheme-to-phoneme library \textit{g2p} by \cite{g2pE2019}. It predicts the pronunciation for out-of-dictionary words using deep learning seq2seq model by TensorFlow (\cite{tensorflow2015-whitepaper}).

Even having the pronunciation for every word will not ensure we find every rhyme intended. Song artists may take their liberty in modifying or skewing the pronunciation to make the rhyme work. Sometimes they can also sing two syllables in one beat or use an unusual pronunciation from different culture to convey a message. As we established in the beginning, we will focus only on information retrievable from the text and ignore these possible deviations in pronunciation.

\section{Syllabification}
Once we have the pronunciations, we can start to compare them. When comparing lines for rhymes, we have to establish a system of alignment so that we analyze only relevant pairs of phonemes. Initially, we created a simple rhyme detector that just traversed both verses backwards phoneme by phoneme and compared them. However, rhyming words do not have to have an equal number of phonemes. For example words in the Table \ref{phon_misalign_table} have a 2-syllable rhyme. However if we compared each phonemes one by one they get misaligned on consonant clusters S-T-R and P-L and we will miss the second syllable rhyme.

\begin{table}[h!]
		\centering
	\begin{tabular}{c r} 
		Word & ARPAbet transcription \\ [0.5ex] 
		\hline
		constrain & K AH N - S T R EY N \\ 
		complain & K AH M - \space\space\space P L EY N \\
	\end{tabular}
	\caption{Example of misalignment when aligning by phonemes.}
	\label{phon_misalign_table}
\end{table}

We need to make sure that we are comparing corresponding parts of verses otherwise we will miss the rhyme. A better approach would be to compare corresponding syllables. Each syllable can be further split into 3 groups ("CVC") -- leading consonant cluster (\textit{onset}), vowel (\textit{nucleus}), and trailing consonant cluster (\textit{code}). Consonant clusters can sometimes be empty. For syllabification we used Python library \textit{syllabify} \footnote{\url{https://github.com/kylebgorman/syllabify}} which conveniently returns syllables in CVC triplets as described above.


\section{Calculating rating for one rhyme}

Finally, after we have extracted pronunciation and syllables, we can continue to analyze the rhyme and rate the song. We decided to first calculate ratings for pairs of verses and then create an overall song rating based on these individual ratings. Another approach would be to analyze the complex statistics of the entire song and rate it at the end all at once. The second method could be better at incorporating the high-level properties like repeating of the refrain. We chose the first approach because it is more straight-forward and gives us a number for each rhyme which can be more interesting for the writer. Additional high-level analysis can be added later if necessary.

So let's focus on the rhyme analysis of two verses -- or rhyme fellows -- as they are typically called. Rhymes are located at the end of each line so there is no need to analyze the entire verse. How far should we look? The first choice would be to look at the last word. However rhymes can extend over more words as we see in \todo[inline]{Find an example of multi-word rhyme where the second word is unaccented}. When we look at the rhyme types, the basic ones do not go further then the first stressed syllable (looking at the line backwards). Notably, even if the rhyme does extend further we can ignore the rest because it will not contribute to the rating. According to our research, the most perfect rhyme is perfect rhyme so it should get the perfect score.\todo[inline]{Mohla byste zaĊít tím, že každému rýmu chcete přiřadit skóre v intervalu 0-1. Pak asi prostě uvést, že (jste se rozhodla, že) perfect rhyme dostane maximální skóre, tedy 1.} If there are more rhyming syllables preceding the perfect rhyme, they cannot make the score better. Similarly, if the rhyme is not perfect, syllables preceding the final stress would already be considered an internal rhyme -- which is also used (mainly in rap lyrics) but less valued than the classical end rhyme and as stated in section \ref{defining_the_requirements}, not a target of analysis in this thesis. We will therefore limit our window to the minimum number of syllables needed to include the stressed syllable in both rhyme fellows. Having a sequence of four unstressed syllables is very unlikely in English language so we limited the output of our word preprocessing (pronunciation + syllabification) to last 4 syllables to speed up the performance.

To determine the rhyme we need to assess the match in sound of individual phonemes.

...

...

To identify similar sounds, we look them up if there is a similarity group containing both of them. These similarity groups were created... \todo[inline]{Describe how it was done. The iterative approach? Or maybe Holtman's hierarchy? panPhon? \cite{mortensen2016panphon}}

 Some words may have multiple possible pronunciations -- in that case we evaluate each possible combination of pronunciations for given line pair. After we assign a rating for each combination, we will keep only the best rated combination of pronunciations and discard the rest. 


stress penalty


The final formula for a rhyme rating is ..simple multiplication...:

\[average(stress\_multiplication\_factor*weighted\_average(similarities))\]


\section{Calculating song rating}
\todo[inline]{rating celej piesne je priemer 2. stlpca, okrem '-' }
\todo[inline]{- rozlišovat terminologicky:
	- (rhyme) rating, tedy rating dvou veršů=řádků, číslo mezi 0 a 1
	- assigned (rhyme) rating, tedy rating, který nakonec danému řádku přidělíte(zatím jako nejvyšší možný z předchozích 1-5 řádků; případně 0, jsou-li všechny ratingy <0.8; případně žádný, jde-li o první řádku skupiny)
	- (rhyme) score, skóre celé písně, tedy průměr všech assigned ratings.}

The next step is to combine these rhyme ratings into one final rating for the entire song. In the previous section we created a function that returns rhyme rating for given two verses. To search for rhymes in the full lyrics we need to decide which verse pairs to check. The most straight-forward approach would be "brute force" -- try each line with all the other lines. Besides its obvious disadvantage of increased time requirements it also detects rhymes that span across tens of lines. It is not strictly defined how many lines apart can the rhyme fellows be to still be considered a rhyme -- the author can even make it a part of his artistic expression  e.g. in "Author's Prologue" by \cite{thomas1952author} the 1\textsuperscript{st} line rhymes with 102\textsuperscript{th}, 2\textsuperscript{nd} with 101\textsuperscript{th} and so on. Realistically, a rhyme between a line at the beginning of the lyrics and 20 lines later would not have a strong effect on the song listener -- it requires a close proximity of rhyme fellows within the poem for the rhyme to be noticed by ear. Since the most common stanzaic form in English is a quatrain, a stanza of four lines (\cite{eastman1970norton}), we decided to set the distance to 5. 


As we decided, for each line, we will look at 5 preceding lines to look for its rhyme fellow. In case multiple of them rhyme, ....the one with the smallest distance will be selected .

...

 Loosing rating by marking weaker rhymes does not make sense so we must add an exception to only keep the better score.

Using the ratings added to the lines a final score will be calculated as the average of lines that have a rating (not an "X").


 Rhymes in songs or poems are typically marked using a rhyme scheme. That means each verse gets assigned a letter -- lines that share the same letter rhyme and those with different letters do not. We also decided to adapt this common notation. In case the song needs more letters than there are in the alphabet we will add another letter and continue alphabetically -- aa, ab, ac, ..., ba, bb, bc, ..., ca, etc.


	
\noindent\rule{14cm}{0.4pt}

Since meter plays an important role in rhymes, another relevant property to examine is the number of syllables. To count syllables for each line we used Python package \textit{syllabify} \footnote{\url{https://github.com/kylebgorman/syllabify}} which returns syllables using ARPAbet transcription. For words not in CMUdict we used a simple heuristic -- since the nucleus of each syllable is most often a vowel (except for syllabic consonants) we counted the number of (groups of) vowels and used it as an estimation for the number of syllables. Although this gives a wrong estimate for some words e.g. \textit{rhythm} or \textit{house}, it performed quite well when we tested it on a few out-of-dictionary words from our dataset. We found it unnecessary to try to further improve the heuristic because the words that are not in CMUdict are often foreign words that do not follow the standard pronunciation rules of English so any application of these rules would probably be of little help.

\todo[inline]{Nemalo by tu mozno byt este nieco o tom ako sme to testovali? Resp. netreba to odtestovat nejak systematickejsie nez od oka?}
